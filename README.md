# Titanic: Machine Learning from Disaster ğŸš¢

This is my implementation of the [Kaggle Titanic competition](https://www.kaggle.com/competitions/titanic) to learn the end-to-end data science process and build strong GitHub habits.

## ğŸ“Œ Goals
- Learn how to structure data science projects
- Practice EDA, preprocessing, feature engineering, and modeling
- Submit to Kaggle and track progress
- Practice documenting and version-controlling my work

## ğŸ“ Project Structure
- `notebooks/`: EDA, modeling, and experiments
- `data/`: Raw data (excluded from GitHub)
- `submissions/`: CSVs for Kaggle submission
- `.gitignore`: Avoids committing unnecessary files

## ğŸ§ª Experiments Summary

| Model             | Public Score | Notes                         |
|------------------|--------------|-------------------------------|
| LogisticRegression | 0.76555      | Basic features only           |
| RandomForest       | 0.78468      | Added Title + FamilySize      |

## ğŸ” What I Learned
- How to preprocess tabular data
- Encoding strategies for categorical variables
- Feature engineering boosts performance
- How to use GitHub + Jupyter cleanly

## ğŸ§­ Next Steps
- Try hyperparameter tuning (GridSearchCV, etc.)
- Use XGBoost or LightGBM
- Build a pipeline for reproducibility

---

*This is a beginner project for practice and learning. Feedback welcome!*